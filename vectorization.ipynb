{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  naturally irresistible your corporate identity...       1\n",
      "1  stock trading gunslinger fanny merrill muzo co...       1\n",
      "2  unbelievable homes made easy wanting show this...       1\n",
      "3  color printing special request additional info...       1\n",
      "4  have money software from here software compati...       1\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"clean_email.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['text'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary and Bag of Words Matrix have been saved to files.\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    return text.split()\n",
    "\n",
    "vocabulary = set()\n",
    "tokenized_sentences = []\n",
    "\n",
    "for entry in data:\n",
    "    tokens = tokenize(data[\"text\"].tolist())  \n",
    "    tokenized_sentences.append(tokens)\n",
    "    vocabulary.update(tokens)  \n",
    "\n",
    "vocabulary = sorted(vocabulary)\n",
    "\n",
    "def build_bag_of_words(tokenized_sentences, vocabulary):\n",
    "    bag_of_words_matrix = []\n",
    "    for tokens in tokenized_sentences:\n",
    "        word_counts = [tokens.count(word) for word in vocabulary]\n",
    "        bag_of_words_matrix.append(word_counts)\n",
    "    return bag_of_words_matrix\n",
    "\n",
    "bag_of_words_matrix = build_bag_of_words(tokenized_sentences, vocabulary)\n",
    "\n",
    "with open(\"vocabulary.txt\", \"w\") as vocab_file:\n",
    "    for word in vocabulary:\n",
    "        vocab_file.write(word + \"\\n\")\n",
    "\n",
    "import csv\n",
    "with open(\"bag_of_words_matrix.csv\", \"w\", newline=\"\") as matrix_file:\n",
    "    writer = csv.writer(matrix_file)\n",
    "    writer.writerow(vocabulary) \n",
    "    writer.writerows(bag_of_words_matrix)  \n",
    "\n",
    "print(\"Vocabulary and Bag of Words Matrix have been saved to files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791\n",
      "791\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary))\n",
    "print(len(bag_of_words_matrix[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
